{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jzfeKDMP2vh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "336b8f60-2ec5-46fc-d51f-66eb95bee947"
      },
      "source": [
        "!pip install -q kss\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elCn_RKOQYBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "   \n",
        "# PyDrive Authentication\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bibi9-QvUk97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_id = '1wV4k91wu5NVNuC-KHSBv2xxqpFSVd0gt'\n",
        "   \n",
        "def ListFolder(parent):\n",
        "    filelist=[]\n",
        "    file_list = drive.ListFile({'q': \"'%s' in parents and trashed=false\" % parent}).GetList()\n",
        "    for f in file_list:\n",
        "        if f['mimeType']=='application/vnd.google-apps.folder': # if folder\n",
        "            filelist.append({\"id\":f['id'],\"title\":f['title'],\"list\":ListFolder(f['id'])})\n",
        "        else:\n",
        "            filelist.append({\"title\":f['title'],\"id\":f['id']})\n",
        "    return filelist\n",
        "   \n",
        "   \n",
        "file_lists = ListFolder(folder_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2pEcF25Ve13",
        "colab_type": "code",
        "outputId": "73f0574a-f2ba-47d2-bae8-4d5c5f473536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "file_lists_from_drive = ListFolder(folder_id)\n",
        "   \n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('~/my_sample_data')\n",
        "try:\n",
        "    os.makedirs(local_download_path)\n",
        "except: pass\n",
        "   \n",
        "for file in file_lists_from_drive:\n",
        "    if file['title'] != 'CM.txt':\n",
        "        continue\n",
        "    print('title: %s, id: %s' % (file['title'], file['id']))\n",
        "    fname = os.path.join(local_download_path, file['title'])\n",
        "    print('downloading to {}'.format(fname))\n",
        "    f_ = drive.CreateFile({'id': file['id']})\n",
        "    f_.GetContentFile(fname)\n",
        "    print(fname)\n",
        "    file_lists.append(fname)\n",
        "   \n",
        "# print file lists\n",
        "print(file_lists)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: CM.txt, id: 1QHq6p67jpE56AI5c1HPhJifTpSYaB9Gl\n",
            "downloading to /root/my_sample_data/CM.txt\n",
            "/root/my_sample_data/CM.txt\n",
            "[{'title': 'pyML.ipynb', 'id': '1OvDhT-diTy51QpzqbRJEdr-do5Ne8QK3'}, {'id': '19s7dmpQxRUWCuoIQL-rgauzpmRQhaqed', 'title': 'seq2seq.krs', 'list': [{'title': 'saved_model.pb', 'id': '1--CqtL0rhwYNz27FA6w28MSlD2cFy4_Z'}, {'id': '1-1Eyueh03K35IaaqKdDvr9DveWL65hW6', 'title': 'assets', 'list': []}, {'id': '1-3-12eddgTS8wG_yoNoWR1DSUSqBKA7c', 'title': 'variables', 'list': [{'title': 'variables.index', 'id': '1-4QOvpsfOu8oSfCDnnp8DxZDSURx4ZEC'}, {'title': 'variables.data-00000-of-00002', 'id': '1-6MHSSjQm2RCP2OEge_0IBVn32x2nmrS'}, {'title': 'variables.data-00001-of-00002', 'id': '1-5jYUWf6tLlPtYvkt7KosVRunplBe55y'}]}]}, {'title': 'CM.txt', 'id': '1QHq6p67jpE56AI5c1HPhJifTpSYaB9Gl'}, '/root/my_sample_data/CM.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7eoBsyzRXnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad96K8WQR4YV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import kss\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import random\n",
        "import time\n",
        "choseong_list = [char for char in \"ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎ\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G5it_d8R4au",
        "colab_type": "code",
        "outputId": "647dc0c9-c730-4036-c18c-a1b2a6094f25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "f = open('../root/my_sample_data/CM.txt', encoding=\"utf-8\")\n",
        "i=0\n",
        "gogo= 0\n",
        "sentence_list = []\n",
        "lowCount = 2\n",
        "longCount = 100\n",
        "while True:\n",
        "    line = f.readline()\n",
        "    if not line: break\n",
        "    if \"<!DOCTYPE\" in line:\n",
        "        gogo = 0\n",
        "    if \"<text>\" in line:\n",
        "        gogo = 1\n",
        "    if \"</text>\" in line:\n",
        "        gogo = 0\n",
        "    if gogo == 0: continue\n",
        "    if line != '\\n':\n",
        "        i=i+1\n",
        "        line = line.replace(u'\\u3000', u\"\")\n",
        "        line = line.replace(u'\\x80', u\"\")\n",
        "        line = line.replace(u'\\x84', u\"\")\n",
        "        line = line.replace(u'\\x88', u\"\")\n",
        "        line = line.replace(u'\\x8a', u\"\")\n",
        "        line = line.replace(u'\\x8b', u\"\")\n",
        "        line = line.replace(u'\\x8c', u\"\")\n",
        "        line = line.replace(u'\\x90', u\"\")\n",
        "        line = line.replace(u'\\x94', u\"\")\n",
        "        line = line.replace(u'\\x97', u\"\")\n",
        "        line = line.replace(u'\\x9a', u\"\")\n",
        "        line = line.replace(u'\\xa0', u\"\")\n",
        "        line = line.replace(u'\\x9e', u\"\")\n",
        "        line = line.replace(u'\\x9d', u\"\")\n",
        "        line = line.replace(u'\\x81', u\"\")\n",
        "        line = line.replace(u'\\x83', u\"\")\n",
        "        line = line.replace(u'\\x8e', u\"\")\n",
        "        line = line.replace(u'\\x91', u\"\")\n",
        "        line = line.replace(u'\\x96', u\"\")\n",
        "        line = line.replace(u'\\x98', u\"\")\n",
        "        line = line.replace(u'\\x9b', u\"\")\n",
        "        line = line.replace(u'\\x9c', u\"\")\n",
        "        line = line.replace(u'¤', u\"\")\n",
        "        line = line.replace(u'¬', u\"\")\n",
        "        line = line.replace(u'¶', u\"\")\n",
        "        line = re.sub('<trunc>.+?<\\/trunc>', '', line, 0, re.S)\n",
        "        line = re.sub('<.+?>', '', line, 0, re.S)\n",
        "        line = re.sub('\\(.+?\\)', '', line, 0, re.S)\n",
        "        line = re.sub('\\[.+?\\]', '', line, 0, re.S)\n",
        "        line = re.sub('\\{.+?\\}', '', line, 0, re.S)\n",
        "        line = re.sub('《.+?》', '', line, 0, re.S)\n",
        "        line = re.sub('[-§¨©°³¸¼´·²～¯¥=+,#/ꮀ\\?:;遮¡^$@*\\\"※~&%ㆍ!『』\\‘|\\(\\)\\[\\]\\<\\>`\\'…《》\\{\\}_「」±√]', '', line,0,re.S)\n",
        "        line = line.lower()\n",
        "        line = re.sub('[a-z]', '', line, 0, re.S)\n",
        "        line = re.sub('[A-Z]', '', line, 0, re.S)\n",
        "        line_split = kss.split_sentences(line)\n",
        "        temp_line = []\n",
        "        for l_sp in line_split:\n",
        "            if len(l_sp) >lowCount and len(l_sp) <longCount:\n",
        "                temp_line.append(l_sp)\n",
        "        sentence_list+=temp_line\n",
        "f.close()\n",
        "print(len(sentence_list))\n",
        "print(sentence_list[:5])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "184921\n",
            "['뭘 좀 올려야지.', '뭘 좀 올렸어.', '다시 돌려 앞으로.', '됐어.', '우리가족은 아빠 엄마 오빠 나.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TmUScDGR4dU",
        "colab_type": "code",
        "outputId": "c6d83aa0-00ab-40ed-c911-2b011fd7ac8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "#print(sentence_list[:5])\n",
        "word_list = []\n",
        "target = []\n",
        "for sentence in sentence_list:\n",
        "    sen2word = \"\"\n",
        "    for word in sentence:\n",
        "        if re.match('[가-힣]',word) is not None :\n",
        "            sen2word+=choseong_list[(int)((ord(word)-ord('가'))/(21*28))]\n",
        "        else :\n",
        "            sen2word+=word\n",
        "    target.append(sentence+'\\n')\n",
        "    word_list.append(sen2word+'\\n')\n",
        "    \n",
        "#print(target[:5])\n",
        "#print(word_list[:5])\n",
        "src_vocab=set()\n",
        "for words in word_list: # 1줄씩 읽음\n",
        "    for char in words: # 1개의 글자씩 읽음\n",
        "        src_vocab.add(char)\n",
        "\n",
        "tar_vocab=set()\n",
        "for line in target:\n",
        "    for char in line:\n",
        "        tar_vocab.add(char)\n",
        "        \n",
        "src_vocab_size = len(src_vocab)+1\n",
        "tar_vocab_size = len(tar_vocab)+1\n",
        "#print(src_vocab_size)\n",
        "#print(tar_vocab_size)\n",
        "src_vocab = sorted(list(src_vocab))\n",
        "tar_vocab = sorted(list(tar_vocab))\n",
        "print(src_vocab)\n",
        "print(tar_vocab[10:20])\n",
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
        "#print(src_to_index)\n",
        "#print(tar_to_index)\n",
        "encoder_input = []\n",
        "for line in word_list: #입력 데이터에서 1줄씩 문장을 읽음\n",
        "    temp_X = []\n",
        "    for w in line: #각 줄에서 1개씩 글자를 읽음\n",
        "        temp_X.append(src_to_index[w]) # 글자를 해당되는 정수로 변환\n",
        "    encoder_input.append(temp_X[:-1])\n",
        "print(encoder_input[:5])\n",
        "decoder_input = []\n",
        "for line in word_list:\n",
        "    temp_X = []\n",
        "    for w in line:\n",
        "      temp_X.append(src_to_index[w])\n",
        "    decoder_input.append(temp_X)\n",
        "print(decoder_input[:5])\n",
        "decoder_target = []\n",
        "for line in target:\n",
        "    temp_X = []\n",
        "    for w in line:\n",
        "        temp_X.append(tar_to_index[w])\n",
        "    decoder_target.append(temp_X)\n",
        "print(decoder_target[:5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n', ' ', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'ᄇ', 'ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
            "['7', '8', '9', 'ᄇ', '가', '각', '간', '갇', '갈', '갉']\n",
            "[[21, 2, 27, 2, 26, 20, 26, 27, 3], [21, 2, 27, 2, 26, 20, 26, 3], [18, 24, 2, 18, 20, 2, 26, 26, 20, 3], [18, 26, 3], [26, 20, 15, 27, 26, 2, 26, 23, 2, 26, 21, 2, 26, 23, 2, 17, 3]]\n",
            "[[21, 2, 27, 2, 26, 20, 26, 27, 3, 1], [21, 2, 27, 2, 26, 20, 26, 3, 1], [18, 24, 2, 18, 20, 2, 26, 26, 20, 3, 1], [18, 26, 3, 1], [26, 20, 15, 27, 26, 2, 26, 23, 2, 26, 21, 2, 26, 23, 2, 17, 3, 1]]\n",
            "[[691, 2, 1263, 2, 1128, 551, 1068, 1298, 3, 1], [691, 2, 1263, 2, 1128, 558, 1083, 3, 1], [339, 966, 2, 390, 551, 2, 1059, 1186, 562, 3, 1], [397, 1083, 3, 1], [1154, 605, 15, 1260, 1188, 2, 1046, 804, 2, 1090, 613, 2, 1125, 804, 2, 231, 3, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVOSDWkBTDRC",
        "colab_type": "code",
        "outputId": "ce259431-e10c-492c-f8fa-be64350b9322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "max_src_len = max([len(line) for line in word_list])-1\n",
        "max_tar_len = max([len(line) for line in target])\n",
        "print(max_src_len)\n",
        "print(max_tar_len)\n",
        "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')\n",
        "\n",
        "encoder_inputer = encoder_input[:len(encoder_input)//5*4]\n",
        "decoder_inputer = decoder_input[:len(decoder_input)//5*4]\n",
        "decoder_targeter = decoder_target[:len(decoder_target)//5*4]\n",
        "\n",
        "val_encoder_inputer = encoder_input[len(encoder_input)//5*4:]\n",
        "val_decoder_inputer = decoder_input[len(decoder_input)//5*4:]\n",
        "val_decoder_targeter = decoder_target[len(decoder_target)//5*4:]\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMgVe5aPxwYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def oneHot_en_in(index,batch_size=32):\n",
        "  return to_categorical(encoder_inputer[index*batch_size:(index+1)*batch_size], num_classes=src_vocab_size)\n",
        "def oneHot_de_in(index,batch_size=32):\n",
        "  return to_categorical(decoder_inputer[index*batch_size:(index+1)*batch_size], num_classes=src_vocab_size)\n",
        "def oneHot_de_out(index,batch_size=32):\n",
        "  return to_categorical(decoder_targeter[index*batch_size:(index+1)*batch_size], num_classes=tar_vocab_size)\n",
        "#encoder_input = to_categorical(encoder_inputer, num_classes=src_vocab_size)\n",
        "#decoder_input = to_categorical(decoder_inputer, num_classes=src_vocab_size)\n",
        "#decoder_target = to_categorical(decoder_targeter, num_classes=tar_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK7Weupmx7lt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm = LSTM(units=100, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n",
        "encoder_states = [state_h, state_c]\n",
        "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 바로 은닉 상태와 셀 상태.\n",
        "\n",
        "decoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "decoder_lstm = LSTM(units=100, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "# 디코더의 첫 상태를 인코더의 은닉 상태, 셀 상태로 합니다.\n",
        "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdejdnTN1HYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shake_list():\n",
        "  random.shuffle(encoder_inputer)\n",
        "  random.shuffle(decoder_inputer)\n",
        "  random.shuffle(decoder_targeter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vrl8V_-vTBW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "055e0105-9d84-4df3-dd8c-294052cb2e90"
      },
      "source": [
        "epochSize = 50\n",
        "bathSize = 32\n",
        "for j in range(epochSize):#len(encoder_inputer)):\n",
        "  print(\"epoch :\",j)\n",
        "  print(\"batch : \",end='')\n",
        "  start = time.time()\n",
        "  shake_list()\n",
        "  for i in range(len(encoder_inputer)//bathSize):\n",
        "    if(i%(len(encoder_inputer)//bathSize//100)==0):\n",
        "      print(\">\",end='')\n",
        "    #model.train_on_batch(x=[encoder_input[(i)*32:(i+1)*32],decoder_input[(i)*32:(i+1)*32]], y= decoder_target[(i)*32:(i+1)*32])\n",
        "    model.train_on_batch(x=[oneHot_en_in(i,batch_size=bathSize),oneHot_de_in(i,batch_size=bathSize)], y= oneHot_de_out(i,batch_size=bathSize))\n",
        "  print(\"걸린시간 :\",time.time()-start)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 0\n",
            "batch : >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>걸린시간 : 481.8747310638428\n",
            "epoch : 1\n",
            "batch : >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>걸린시간 : 474.6745607852936\n",
            "epoch : 2\n",
            "batch : >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztp2A9oOYL00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.fit(x=[encoder_input, decoder_input], y=decoder_target,  epochs=50, validation_split=0.2, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU6LN4FAbmrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhWXTgXdiGh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYPSGxI-jJKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(100,))\n",
        "decoder_state_input_c = Input(shape=(100,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
        "decoder_states = [state_h, state_c]\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOzpC1dHjKQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nox-fAzTjLqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def str2cho(input_str):\n",
        "    #문장을 입력받으면 초성 문자열로반환하는 코드\n",
        "    cho = \"\"\n",
        "    for word in input_str:\n",
        "        if re.match('[가-힣]',word) is not None :\n",
        "            cho+=(choseong_list[(int)((ord(word)-ord('가'))/(21*28))])\n",
        "        else :\n",
        "            cho+=(word)\n",
        "    return cho"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W2wUDQwjMg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq,strWORD):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    input_seq = to_categorical(input_seq, num_classes=src_vocab_size)\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # 첫글자에 해당하는 원-핫 벡터 생성\n",
        "    target_seq = np.zeros((1, 1, src_vocab_size))\n",
        "    target_seq[0, 0, src_to_index[str2cho(strWORD[0])]] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    cho_sen = \"\"\n",
        "    cho_sen+=str2cho(strWORD[0])\n",
        "    itr = 0\n",
        "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = index_to_tar[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # <eos>에 도달하거나 입력 글자를 넘으면 중단.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) >= len(strWORD)):\n",
        "            stop_condition = True\n",
        "        else:\n",
        "          itr+=1\n",
        "\n",
        "        # 길이가 1인 타겟 시퀀스를 업데이트 합니다.\n",
        "        target_seq = np.zeros((1, 1, src_vocab_size))\n",
        "        \n",
        "        target_seq[0, 0, src_to_index[str2cho((strWORD[itr]))]] = 1.\n",
        "        cho_sen+=str2cho(strWORD[itr])\n",
        "        # 상태를 업데이트 합니다.\n",
        "        states_value = [h, c]\n",
        "    #print(cho_sen)\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA3KkbtkjNrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 0\n",
        "for seq_index in [1,2,16000,4,5]:#105,70000,15002,40015,5]: # 입력 문장의 인덱스\n",
        "    i+=1\n",
        "    print('입력 문장:', word_list[seq_index])\n",
        "    print('정답 문장:', target[seq_index][:len(target[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "\n",
        "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq,word_list[seq_index])\n",
        "    #print('입력 문장:', word_list[seq_index])\n",
        "    #print('정답 문장:', target[seq_index][:len(target[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)]) # '\\n'을 빼고 출력\n",
        "    print(35 * \"-\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aIrD8vOo0Qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()\n",
        "from os import path\n",
        "from google.colab import drive\n",
        "\n",
        "notebooks_dir_name = 'MLTEXT'\n",
        "drive.mount('/content/gdrive')\n",
        "notebooks_base_dir = path.join('./gdrive/My Drive/', notebooks_dir_name)\n",
        "if not path.exists(notebooks_base_dir):\n",
        "  print('Check your google drive directory. See you file explorer')\n",
        "\n",
        "model.save(path.join(notebooks_base_dir, \"seq2seq.krs\"))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}